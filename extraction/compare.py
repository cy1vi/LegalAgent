# compare_rule_vs_llm.py
import os
import json
import random
import time
from pathlib import Path
from openai import OpenAI
from dotenv import load_dotenv

load_dotenv()

client = OpenAI(
    api_key=os.getenv("OPENROUTER_API_KEY"),
    base_url="https://openrouter.ai/api/v1"  
)



PROMPT_TEMPLATE = """ä½ æ˜¯ä¸€ä¸ªæ³•å¾‹ä¿¡æ¯æŠ½å–ä¸“å®¶ï¼Œè¯·ä¸¥æ ¼æŒ‰ä»¥ä¸‹è¦æ±‚å¤„ç†ï¼š

ä»»åŠ¡ï¼šä»æ¡ˆä»¶äº‹å®ä¸­æå–ç»“æ„åŒ–ä¿¡æ¯ã€‚
è§„åˆ™ï¼š
1. è¾“å‡ºå¿…é¡»æ˜¯åˆæ³• JSONï¼Œç»“æ„ä¸ç¤ºä¾‹å®Œå…¨ä¸€è‡´ã€‚
2. æ¯ä¸ªå­—æ®µï¼š
   - è‹¥äº‹å®ä¸­æ˜ç¡®æåŠ â†’ å¡«å†™**æœ€ç›¸å…³çš„åŸæ–‡çŸ­è¯­**ï¼ˆå°½é‡ç®€çŸ­ï¼Œâ‰¤7å­—ï¼‰
   - è‹¥æœªæåŠ â†’ å¡« null
3. ç¦æ­¢æ¨ç†ã€æ€»ç»“ã€æ”¹å†™ï¼Œåªæå–å­—é¢å†…å®¹ã€‚

è¾“å‡ºç»“æ„ï¼š
{
  "act": {
    "has_violence": "...",
    "violence_level": "...",
    "has_threat": "...",
    "is_secret": "...",
    "is_deceptive": "...",
    "has_conspiracy": "...",
    "used_tool": "..."
  },
  "object": {
    "is_person": "...",
    "is_property": "...",
    "is_public_order": "...",
    "is_state_interest": "...",
    "property_type": "..."
  },
  "result": {
    "injury": "...",
    "injury_level": "...",
    "death": "...",
    "property_transferred": "...",
    "amount_mentioned": "...",
    "has_restitution": "...",
    "has_confession": "...",
    "has_forgiveness": "..."
  },
  "participation": {
    "has_multiple_offenders": "...",
    "has_organization": "...",
    "role_description": "..."
  },
  "context": {
    "is_indoor": "...",
    "is_public_place": "...",
    "is_night": "...",
    "is_online": "..."
  }
}

"""

def extract_with_llm(fact_text: str) -> dict:
    # âœ… æå‰å®šä¹‰ expected â€”â€” è¿™æ˜¯å…³é”®ï¼
    expected = {
        "act": ["has_violence", "violence_level", "has_threat", "is_secret", "is_deceptive", "has_conspiracy", "used_tool"],
        "object": ["is_person", "is_property", "is_public_order", "is_state_interest", "property_type"],
        "result": ["injury", "injury_level", "death", "property_transferred", "amount_mentioned", "has_restitution", "has_confession", "has_forgiveness"],
        "participation": ["has_multiple_offenders", "has_organization", "role_description"],
        "context": ["is_indoor", "is_public_place", "is_night", "is_online"]
    }

    try:
        completion = client.chat.completions.create(
            model=os.getenv("LLM_MODEL"),
            messages=[
                {"role": "system", "content": PROMPT_TEMPLATE},
                {"role": "user", "content": "ç°åœ¨è¯·å¤„ç†ä»¥ä¸‹äº‹å®ï¼š" + fact_text}
            ],
            response_format={"type": "json_object"},
            temperature=0.0,
            max_tokens=1000
        )
        content = completion.choices[0].message.content
        if not content:
            raise ValueError("Empty response from LLM")
        
        result = json.loads(content)

        # è¡¥å…¨ç¼ºå¤±å­—æ®µä¸º null
        for group, keys in expected.items():
            if group not in result:
                result[group] = {}
            for k in keys:
                result[group].setdefault(k, None)
        return result

    except Exception as e:
        # å‡ºé”™æ—¶ç›´æ¥è¿”å›å…¨ nullï¼Œä¸ä¸­æ–­æµç¨‹
        print(f"âš ï¸ LLM æŠ½å–å¤±è´¥ï¼Œè·³è¿‡æ­¤æ¡: {str(e)[:150]}")
        return {
            "act": {k: None for k in expected["act"]},
            "object": {k: None for k in expected["object"]},
            "result": {k: None for k in expected["result"]},
            "participation": {k: None for k in expected["participation"]},
            "context": {k: None for k in expected["context"]}
        }

# ======================
# åˆ¤æ–­æ˜¯å¦æœ‰æœ‰æ•ˆä¿¡æ¯ï¼ˆç”¨äºå¯¹æ¯”ï¼‰
# ======================
def has_meaningful_value(val):
    if val is None:
        return False
    if isinstance(val, bool):
        return val
    if isinstance(val, str):
        return bool(val.strip())
    return bool(val)

def find_diff_fields(rule_res: dict, llm_res: dict) -> list:
    diff = []
    groups = ["act", "object", "result", "participation", "context"]
    for group in groups:
        rule_group = rule_res.get(group, {})
        llm_group = llm_res[group]
        for key in llm_group:
            v1 = rule_group.get(key)
            v2 = llm_group[key]
            has1 = has_meaningful_value(v1)
            has2 = has_meaningful_value(v2)
            if has1 != has2:
                diff.append(f"{group}.{key}")
    return diff

# ======================
# ä¸»æµç¨‹
# ======================
def main():
    INPUT_JSONL = "F:\\LegalAgent\\output\\universal_facts.jsonl"      
    OUTPUT_JSONL = "F:\\LegalAgent\\output\\comparison_200.jsonl"
    SAMPLE_SIZE = 200

    # 1. è¯»å–æ‰€æœ‰è¡Œ
    print("ğŸ“‚ æ­£åœ¨åŠ è½½ JSONL æ•°æ®...")
    records = []
    with open(INPUT_JSONL, "r", encoding="utf-8") as f:
        for line in f:
            if line.strip():
                records.append(json.loads(line))
    
    total = len(records)
    print(f"âœ… å…±åŠ è½½ {total} æ¡è®°å½•")

    # 2. éšæœºæŠ½æ ·
    sampled = random.sample(records, min(SAMPLE_SIZE, total))
    print(f"ğŸ² éšæœºæŠ½å– {len(sampled)} æ¡è¿›è¡Œå¯¹æ¯”...")

    # 3. å¤„ç†æ¯æ¡æ ·æœ¬
    with open(OUTPUT_JSONL, "w", encoding="utf-8") as out:
        for i, record in enumerate(sampled, 1):
            fact = record["fact"]
            rule_universal = record["universal_fact"]
            
            print(f"[{i}/{len(sampled)}] æŠ½å–ä¸­...")
            llm_universal = extract_with_llm(fact)
            time.sleep(0.3)  # é˜² API é™æµ

            # å¯¹æ¯”
            diff_fields = find_diff_fields(rule_universal, llm_universal)
            has_diff = len(diff_fields) > 0

            # æ„é€ è¾“å‡º
            output_record = {
                "original_record": record,          # å®Œæ•´åŸå§‹è®°å½•ï¼ˆå« meta, fact, universal_factï¼‰
                "llm_extracted": llm_universal,     # å¤§æ¨¡å‹æŠ½å–ç»“æœï¼ˆå­—ç¬¦ä¸²/nullï¼‰
                "has_diff": has_diff,
                "diff_fields": diff_fields
            }
            out.write(json.dumps(output_record, ensure_ascii=False) + "\n")
    
    print(f"âœ… å¯¹æ¯”å®Œæˆï¼ç»“æœå·²ä¿å­˜è‡³ {OUTPUT_JSONL}")
    
    # ç»Ÿè®¡å·®å¼‚æ¯”ä¾‹
    with open(OUTPUT_JSONL, "r", encoding="utf-8") as f:
        results = [json.loads(line) for line in f]
    diff_count = sum(1 for r in results if r["has_diff"])
    print(f"ğŸ“Š å­˜åœ¨å·®å¼‚çš„æ ·æœ¬: {diff_count} / {len(results)} ({100 * diff_count / len(results):.1f}%)")

if __name__ == "__main__":
    main()