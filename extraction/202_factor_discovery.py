import json
import os
import random
from collections import defaultdict
from tqdm import tqdm

# --- è‡ªå®šä¹‰æ¨¡å— ---
from agent import LegalCaseSchemaExtractor
from build_one_prompt import build_prompt_no_template as bp  

# --- é…ç½® ---
INPUT_FILE = r"D:\deeplearning\project_learning\LegalAgent\dataset\final_all_data\first_stage\train.json"

OUTPUT_DIR = r"D:\deeplearning\project_learning\LegalAgent\statistics_analyze\discovered_factors_by_accusation_no_template"
TEMP_OUTPUT_DIR = os.path.join(OUTPUT_DIR, "temp_individual_outputs")
CATEGORY_OUTPUT_DIR = os.path.join(OUTPUT_DIR, "by_accusation")
SUMMARY_OUTPUT_FILE = os.path.join(OUTPUT_DIR, "all_discovered_factors_no_template.json")

SAMPLES_PER_ACCUSATION = 20  # æ¯ä¸ªç½ªåæœ€å¤šé‡‡æ ·æ•°é‡


def load_cases(file_path):
    """ä» JSONL æ–‡ä»¶åŠ è½½æ¡ˆä»¶"""
    cases = []
    with open(file_path, 'r', encoding='utf-8') as f:
        for line in f:
            if line.strip():
                cases.append(json.loads(line))
    return cases


def categorize_cases_by_accusation(cases):
    """æŒ‰å…·ä½“ç½ªååˆ†ç±»ï¼ˆå–ç¬¬ä¸€ä¸ªæŒ‡æ§ä¸ºä¸»ç½ªï¼‰"""
    categorized = defaultdict(list)
    for case in cases:
        meta = case.get("meta", {})
        accusations = meta.get("accusation", [])
        if accusations:
            main_acc = accusations[0]
            categorized[main_acc].append(case)
        else:
            categorized["æœªçŸ¥ç½ªå"].append(case)
    return dict(categorized)


def sample_cases_by_accusation(categorized_cases, samples_per_accusation):
    """å¯¹æ¯ä¸ªç½ªåé‡‡æ ·"""
    sampled = {}
    for accusation, case_list in categorized_cases.items():
        n = len(case_list)
        if n <= samples_per_accusation:
            sampled[accusation] = case_list
            print(f"ç½ªå '{accusation}' æ¡ˆä¾‹æ•° ({n}) â‰¤ {samples_per_accusation}ï¼Œä½¿ç”¨å…¨éƒ¨ã€‚")
        else:
            sampled[accusation] = random.sample(case_list, samples_per_accusation)
            print(f"ç½ªå '{accusation}' å·²é‡‡æ · {samples_per_accusation} æ¡ã€‚")
    return sampled


def llm_call(case_fact, accusation_name):
    """å®‰å…¨æ‹¼æ¥ promptï¼Œé¿å…æ ¼å¼åŒ–é”™è¯¯"""
    base_prompt = bp(accusation_name)
    extractor = LegalCaseSchemaExtractor()
    
    # ä¿®æ”¹ï¼šä½¿ç”¨ analyze_case æ›¿ä»£ extract_schema
    # extract_schema ä¼šå¼ºåˆ¶æ·»åŠ é¢å¤–çš„æ ¼å¼åŒ–æŒ‡ä»¤ï¼Œå¹²æ‰°æˆ‘ä»¬è‡ªå®šä¹‰çš„ prompt
    # analyze_case åˆ™ç›´æ¥ä¼ é€’ system_prompt å’Œ user_content
    response = extractor.analyze_case(system_prompt=base_prompt, user_content=case_fact,stream=False)
    
    # response = extractor.extract_schema(case_fact, prompt_override=base_prompt, stream=False)  
    return response



def process_sampled_cases(sampled_cases):
    """å¤„ç†æ¯ä¸ªç½ªåçš„é‡‡æ ·æ¡ˆä»¶"""
    os.makedirs(TEMP_OUTPUT_DIR, exist_ok=True)
    os.makedirs(CATEGORY_OUTPUT_DIR, exist_ok=True)

    all_results = {}

    for accusation, cases in sampled_cases.items():
        print(f"\n--- å¼€å§‹å¤„ç†ç½ªå: {accusation} (å…± {len(cases)} æ¡) ---")
        results = []

        for i, case in enumerate(tqdm(cases, desc=f"{accusation}", ncols=100)):
            fact = case.get("fact", "")
            meta = case.get("meta", {})
            original_accusations = meta.get("accusation", [accusation])

            try:
                llm_output = llm_call(fact, accusation)
                # å°è¯•è§£æ JSON
                if isinstance(llm_output, str):
                    try:
                        parsed = json.loads(llm_output)
                        llm_output = parsed
                    except json.JSONDecodeError:
                        pass
            except Exception as e:
                llm_output = {"error": f"LLM è°ƒç”¨å¼‚å¸¸: {str(e)}"}

            result_entry = {
                "case_index": i,
                "case_id": f"{accusation}_sample_{i}",
                "original_accusations": original_accusations,
                "fact": fact,
                "llm_analysis": llm_output
            }

            # ä¿å­˜å•æ¡
            temp_path = os.path.join(TEMP_OUTPUT_DIR, f"{accusation}_sample_{i}.json")
            with open(temp_path, 'w', encoding='utf-8') as f:
                try:
                    json.dump(result_entry, f, ensure_ascii=False, indent=2)
                except TypeError:
                    result_entry["llm_analysis"] = str(result_entry["llm_analysis"])
                    json.dump(result_entry, f, ensure_ascii=False, indent=2)

            results.append(result_entry)

        # ä¿å­˜è¯¥ç½ªåæ±‡æ€»
        category_path = os.path.join(CATEGORY_OUTPUT_DIR, f"{accusation}_factors.json")
        with open(category_path, 'w', encoding='utf-8') as f:
            json.dump(results, f, ensure_ascii=False, indent=2)

        all_results[accusation] = results
        print(f"ç½ªå '{accusation}' ç»“æœå·²ä¿å­˜è‡³: {category_path}")

    # ä¿å­˜æ€»æ±‡æ€»
    with open(SUMMARY_OUTPUT_FILE, 'w', encoding='utf-8') as f:
        json.dump(all_results, f, ensure_ascii=False, indent=2)

    print(f"\nâœ… æ‰€æœ‰ç½ªåå¤„ç†å®Œæˆï¼")
    print(f"æ€»æ±‡æ€»æ–‡ä»¶: {SUMMARY_OUTPUT_FILE}")


def main():
    print("ğŸš€ å¯åŠ¨ã€æ— æ¨¡æ¿ã€‘æŒ‰ç½ªåå› ç´ å‘ç°æµç¨‹...")

    # 1. åŠ è½½æ¡ˆä»¶
    print("1. åŠ è½½æ¡ˆä»¶æ•°æ®...")
    all_cases = load_cases(INPUT_FILE)
    print(f"   å…±åŠ è½½ {len(all_cases)} æ¡æ¡ˆä»¶ã€‚")

    # 2. æŒ‰ç½ªååˆ†ç»„
    print("2. æŒ‰å…·ä½“ç½ªååˆ†ç»„...")
    categorized = categorize_cases_by_accusation(all_cases)
    print(f"   å…±è¯†åˆ«å‡º {len(categorized)} ä¸ªç½ªåã€‚")

    # 3. é‡‡æ ·ï¼ˆå¯é€‰ï¼šåªå¤„ç†é«˜é¢‘ç½ªåï¼Œé¿å…å†·é—¨ç½ªåæµªè´¹èµ„æºï¼‰
    # è¿™é‡Œæˆ‘ä»¬å¤„ç†æ‰€æœ‰ç½ªåï¼Œä½†ä½ å¯ä»¥åŠ è¿‡æ»¤æ¡ä»¶ï¼Œä¾‹å¦‚ï¼š
    # filtered = {k: v for k, v in categorized.items() if len(v) >= 5}
    sampled = sample_cases_by_accusation(categorized, SAMPLES_PER_ACCUSATION)

    # 4. å¤„ç†
    print("3. è°ƒç”¨ LLM æå–å› ç´ ï¼ˆæ— æ¨¡æ¿ï¼‰...")
    process_sampled_cases(sampled)

    print("\nğŸ‰ æµç¨‹ç»“æŸï¼")


if __name__ == "__main__":
    main()