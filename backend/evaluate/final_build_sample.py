import os
import json
import random
import numpy as np
import torch
import torch.nn.functional as F
from tqdm import tqdm
from collections import defaultdict

# ç»§æ‰¿åŸºç±»ï¼Œä½†æˆ‘ä»¬ä¼šè¦†ç›–å¤§éƒ¨åˆ†è€—èµ„æºçš„æ–¹æ³•
from prepare_datasets_v2 import GoldDatasetBuilder
from config import EvalConfig, CleanConfig

class FastSampler(GoldDatasetBuilder):
    def __init__(self, data_path, device='cuda'):
        # ä¸è°ƒç”¨ super().__init__ï¼Œå› ä¸ºæˆ‘ä»¬è¦æ§åˆ¶åŠ è½½è¿‡ç¨‹ï¼Œé¿å…å†…å­˜çˆ†ç‚¸
        self.data_path = data_path
        self.all_data = []
        self.accusation_index = {}
        self.fact_embeddings = None
        
        # ç¨€ç–ç‰¹å¾ç›¸å…³ (ä½¿ç”¨æ–‡ä»¶æŒ‡é’ˆè€Œéå…¨é‡åŠ è½½)
        self.sparse_file_offsets = []
        self.sparse_file_handle = None
        
        self.device = torch.device(device if torch.cuda.is_available() else 'cpu')
        print(f"ğŸš€ ä½¿ç”¨è®¾å¤‡: {self.device}")
        
        # 1. åŠ è½½åŸºç¡€æ•°æ® (å¿…é¡»)
        self.load_and_index()
        
        # 2. ä¼˜åŒ–åŠ è½½ Embedding å’Œ Sparse
        self._load_resources_optimized()

    def _load_resources_optimized(self):
        """ä¼˜åŒ–åŠ è½½ï¼šEmbedding å°è¯• mmapï¼ŒSparse ä½¿ç”¨æ–‡ä»¶ç´¢å¼•"""
        # A. åŠ è½½ Embedding
        embedding_path = r"F:\LegalAgent\backend\data\fact_embeddings\fact_embeddings_bge-m3.npy"
        if os.path.exists(embedding_path):
            try:
                # å°è¯•å…¨é‡åŠ è½½ï¼Œå¦‚æœå†…å­˜ä¸å¤Ÿåˆ™æŠ¥é”™è¢«æ•è·
                self.fact_embeddings = np.load(embedding_path)
                print(f"å·²åŠ è½½åµŒå…¥å‘é‡: {embedding_path}, shape: {self.fact_embeddings.shape}")
            except Exception:
                print("âš ï¸ å†…å­˜ç´§å¼ ï¼Œä½¿ç”¨ mmap æ¨¡å¼åŠ è½½åµŒå…¥å‘é‡ (é€Ÿåº¦ç¨æ…¢ä½†ä¸ä¼šå´©æºƒ)")
                self.fact_embeddings = np.load(embedding_path, mmap_mode='r')
        
        # B. æ„å»º Sparse ç‰¹å¾ç´¢å¼• (ä¸åŠ è½½å†…å®¹)
        sparse_path = r"F:\LegalAgent\backend\sparse-embedding\data\train_sparse_features.jsonl"
        if os.path.exists(sparse_path):
            print(f"æ­£åœ¨æ„å»º Sparse ç‰¹å¾ç´¢å¼• (é¿å…å†…å­˜å ç”¨): {sparse_path}")
            self.sparse_file_handle = open(sparse_path, 'r', encoding='utf-8')
            self.sparse_file_offsets = []
            
            # å¿«é€Ÿæ‰«ææ–‡ä»¶ä½ç½®
            while True:
                offset = self.sparse_file_handle.tell()
                line = self.sparse_file_handle.readline()
                if not line:
                    break
                self.sparse_file_offsets.append(offset)
            print(f"Sparse ç´¢å¼•æ„å»ºå®Œæˆ: {len(self.sparse_file_offsets)} æ¡")

    def get_sparse_item(self, idx):
        """æŒ‰éœ€ä»ç£ç›˜è¯»å–ç¨€ç–ç‰¹å¾"""
        if self.sparse_file_handle is None or idx >= len(self.sparse_file_offsets):
            return {}
        self.sparse_file_handle.seek(self.sparse_file_offsets[idx])
        line = self.sparse_file_handle.readline()
        try:
            return json.loads(line)
        except:
            return {}

    def _calculate_schema_keywords_score_fast(self, q_idx, c_idx):
        """
        é‡å†™è¯„åˆ†é€»è¾‘ï¼šç›´æ¥ä½¿ç”¨ç´¢å¼•ï¼Œé¿å… O(N) æŸ¥æ‰¾
        """
        score = 0
        
        # æŒ‰éœ€è¯»å–
        query_sparse = self.get_sparse_item(q_idx)
        candidate_sparse = self.get_sparse_item(c_idx)
        
        # è·å–sparse_extractionéƒ¨åˆ†
        query_extraction = query_sparse.get('sparse_extraction', {})
        candidate_extraction = candidate_sparse.get('sparse_extraction', {})
        
        # 1. å…³é”®è¯é‡åˆåº¦
        q_kws = set(query_extraction.get('keyword_counts', {}).keys())
        c_kws = set(candidate_extraction.get('keyword_counts', {}).keys())
        
        if q_kws and c_kws:
            intersection = len(q_kws & c_kws)
            union = len(q_kws | c_kws)
            if union > 0:
                score += (intersection / union) * 15
        
        # 2. çŠ¯ç½ªç±»å‹é‡åˆåº¦
        q_crimes = set(query_extraction.get('crime_counts', {}).keys())
        c_crimes = set(candidate_extraction.get('crime_counts', {}).keys())
        
        if q_crimes and c_crimes:
            intersection = len(q_crimes & c_crimes)
            union = len(q_crimes | c_crimes)
            if union > 0:
                score += (intersection / union) * 15
                
        return min(30, score)

    def _batch_embedding_score_torch(self, query_emb_tensor, candidate_embs_tensor):
        """GPU æ‰¹é‡è®¡ç®— Embedding åˆ†æ•°"""
        q_norm = F.normalize(query_emb_tensor, p=2, dim=1)
        c_norm = F.normalize(candidate_embs_tensor, p=2, dim=1)
        similarity = torch.mm(q_norm, c_norm.t()).squeeze(0)
        
        scores = torch.zeros_like(similarity)
        mask_1 = similarity >= 0.95
        scores[mask_1] = 30.0
        mask_2 = (similarity >= 0.90) & (similarity < 0.95)
        scores[mask_2] = 25.0 + (similarity[mask_2] - 0.90) * 100.0
        mask_3 = (similarity >= 0.80) & (similarity < 0.90)
        scores[mask_3] = 15.0 + (similarity[mask_3] - 0.80) * 100.0
        mask_4 = (similarity >= 0.70) & (similarity < 0.80)
        scores[mask_4] = 5.0 + (similarity[mask_4] - 0.70) * 100.0
        mask_5 = similarity < 0.70
        scores[mask_5] = torch.clamp((similarity[mask_5] - 0.60) * 100.0, min=0.0)
        return scores

    def run_fast_sampling(self, output_path, num_queries=100, positives_per_query=10, run_clean=False,
                          initial_pool_factor=3, top_k_for_fine=500, quality_metric_topk=5):
        
        if not self.all_data:
            self.load_and_index()

        if self.fact_embeddings is None:
            raise ValueError("å¿…é¡»åŠ è½½ Embedding æ‰èƒ½ä½¿ç”¨å¿«é€Ÿé‡‡æ ·æ¨¡å¼")

        # 1. åˆé€‰ Query (ä¼˜å…ˆé€‰æ‹©å•æ ‡ç­¾ä¸”è¦†ç›–ä¸åŒç½ªå)
        acc_to_indices = defaultdict(list)
        all_single_indices = []
        
        for idx, item in enumerate(self.all_data):
            accs = item.get('meta', {}).get('accusation', [])
            # ä»…ä¿ç•™å•æ ‡ç­¾æ•°æ®
            if len(accs) == 1:
                acc_name = accs[0]
                acc_to_indices[acc_name].append(idx)
                all_single_indices.append(idx)

        available_accs = list(acc_to_indices.keys())
        print(f"å‘ç° {len(available_accs)} ç§å•æ ‡ç­¾ç½ªåï¼Œå…± {len(all_single_indices)} æ¡æ•°æ®")

        target_count = num_queries * initial_pool_factor
        initial_queries = []
        
        # ç­–ç•¥A: å°½é‡è¦†ç›–æ¯ç§ç½ªåè‡³å°‘å–1ä¸ª
        for acc in available_accs:
            initial_queries.append(random.choice(acc_to_indices[acc]))
            
        # ç­–ç•¥B: å¦‚æœæ•°é‡ä¸å¤Ÿï¼Œä»å‰©ä½™å•æ ‡ç­¾æ•°æ®ä¸­éšæœºè¡¥å……
        current_count = len(initial_queries)
        if current_count < target_count:
            needed = target_count - current_count
            # æ’é™¤å·²é€‰çš„
            chosen_set = set(initial_queries)
            remaining_candidates = [i for i in all_single_indices if i not in chosen_set]
            
            if len(remaining_candidates) >= needed:
                initial_queries.extend(random.sample(remaining_candidates, needed))
            else:
                initial_queries.extend(remaining_candidates)
        
        # å¦‚æœæ•°é‡è¶…äº†ï¼ˆæ¯”å¦‚ç½ªåç§ç±»ç‰¹åˆ«å¤šï¼‰ï¼Œéšæœºæˆªæ–­
        if len(initial_queries) > target_count:
            initial_queries = random.sample(initial_queries, target_count)
        
        print(f"åˆé€‰ {len(initial_queries)} æ¡å•æ ‡ç­¾ queryï¼Œå¼€å§‹å¤„ç†...")

        query_results = []
        
        # 2. ä¸»å¾ªç¯
        for q_idx in tqdm(initial_queries, desc="Processing"):
            query_item = self.all_data[q_idx]
            q_accs = query_item.get('meta', {}).get('accusation', [])

            # A. æ™ºèƒ½æ„å»ºå€™é€‰é›† (é˜²æ­¢å†…å­˜çˆ†ç‚¸)
            candidate_indices = set()
            for acc in q_accs:
                cands = self.accusation_index.get(acc, [])
                # å…³é”®ä¼˜åŒ–ï¼šå¦‚æœæŸç½ªåå€™é€‰å¤ªå¤šï¼Œå…ˆé‡‡æ ·å†åˆå¹¶
                if len(cands) > 10000: 
                    cands = random.sample(cands, 10000)
                candidate_indices.update(cands)
            
            if q_idx in candidate_indices:
                candidate_indices.remove(q_idx)
            
            candidate_list = list(candidate_indices)
            if not candidate_list:
                continue
            
            # äºŒæ¬¡ä¿é™©ï¼šæ€»å€™é€‰æ•°é™åˆ¶
            if len(candidate_list) > 30000:
                candidate_list = random.sample(candidate_list, 30000)

            # B. GPU ç²—ç­› (Embedding)
            q_emb = self.fact_embeddings[q_idx]
            c_embs = self.fact_embeddings[candidate_list]
            
            with torch.no_grad():
                q_tensor = torch.from_numpy(q_emb).unsqueeze(0).to(self.device)
                c_tensor = torch.from_numpy(c_embs).to(self.device)
                emb_scores = self._batch_embedding_score_torch(q_tensor, c_tensor).cpu().numpy()

            # C. é€‰å– Top-K è¿›å…¥ç²¾æ’
            c_scores_indices = list(zip(emb_scores, candidate_list))
            c_scores_indices.sort(key=lambda x: x[0], reverse=True)
            top_k_candidates = c_scores_indices[:top_k_for_fine]

            # D. CPU ç²¾æ’ (Schema + Legal)
            final_candidates = []
            for emb_score, c_idx in top_k_candidates:
                candidate_item = self.all_data[c_idx]
                
                # ä½¿ç”¨ä¼˜åŒ–åçš„å¿«é€Ÿè¯„åˆ†æ–¹æ³• (ä¼ å…¥ç´¢å¼•)
                schema_score = self._calculate_schema_keywords_score_fast(q_idx, c_idx)
                
                legal_score = self._calculate_accusation_articles_imprisonment_score(
                    query_item.get('meta', {}), candidate_item.get('meta', {})
                )
                
                total_score = emb_score + schema_score + legal_score
                
                final_candidates.append({
                    'candidate_item': candidate_item,
                    'total_score': float(total_score),
                    'score_info': {
                        'total_score': float(total_score),
                        'embedding_score': float(emb_score),
                        'schema_keywords_score': float(schema_score),
                        'acc_article_imp_score': float(legal_score)
                    }
                })

            final_candidates.sort(key=lambda x: x['total_score'], reverse=True)
            positives = final_candidates[:positives_per_query]
            
            if not positives:
                continue

            # è®¡ç®—è´¨é‡åˆ†
            top_for_quality = final_candidates[:max(quality_metric_topk, 1)]
            quality = float(sum(x['total_score'] for x in top_for_quality) / len(top_for_quality))

            query_results.append({
                'query_idx': q_idx,
                'query_item': query_item,
                'positives': [x['candidate_item'] for x in positives],
                'score_details': [x['score_info'] for x in positives],
                'quality': quality
            })

        # 3. æœ€ç»ˆç­›é€‰ä¸ä¿å­˜
        query_results.sort(key=lambda x: x['quality'], reverse=True)
        final_results = query_results[:num_queries]

        dataset = []
        for rec in final_results:
            dataset.append({
                "query": rec['query_item'],
                "query_idx": rec['query_idx'],
                "positives": rec['positives'],
                "positives_count": len(rec['positives']),
                "score_details": rec['score_details'],
                "quality": rec['quality']
            })

        os.makedirs(os.path.dirname(output_path), exist_ok=True)
        with open(output_path, 'w', encoding='utf-8') as f:
            for item in dataset:
                f.write(json.dumps(item, ensure_ascii=False) + '\n')

        print(f"å®Œæˆï¼šåˆé€‰ {len(initial_queries)} -> æœ€ç»ˆ {len(dataset)} ï¼Œä¿å­˜åˆ° {output_path}")

        if run_clean:
            self._run_cleaner(output_path)

    def _run_cleaner(self, input_path):
        print("\n=== è§¦å‘è‡ªåŠ¨æ¸…æ´—æµç¨‹ ===")
        old_input = getattr(CleanConfig, "INPUT_FILE", None)
        CleanConfig.INPUT_FILE = input_path
        CleanConfig.OUTPUT_CLEAN_FILE = input_path.replace(".jsonl", ".cleaned.jsonl")
        CleanConfig.OUTPUT_DIRTY_FILE = input_path.replace(".jsonl", ".dirty.jsonl")

        try:
            import importlib
            import clean_prepared_datasets
            importlib.reload(clean_prepared_datasets)
            clean_prepared_datasets.clean_data()
        except Exception as e:
            print(f"æ¸…æ´—è¿‡ç¨‹å‡ºé”™: {e}")
        finally:
            if old_input: CleanConfig.INPUT_FILE = old_input

if __name__ == "__main__":
    TRAIN_PATH = r"F:\LegalAgent\dataset\final_all_data\first_stage\train.json"
    OUTPUT_PATH = r"F:\LegalAgent\backend\evaluate\sample_100x10_fast.jsonl"
    
    sampler = FastSampler(TRAIN_PATH)
    sampler.run_fast_sampling(
        OUTPUT_PATH, 
        num_queries=100, 
        positives_per_query=10,
        run_clean=True
    )